{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6ynSlKEO80GK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-30 23:15:30.962983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-06-30 23:15:31.643586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2025-06-30 23:15:31.643662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2025-06-30 23:15:31.643669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "from Model_NoDef import DFNet\n",
        "from plot_result import plot_history\n",
        "from data_loader import load_npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY2pY7O4KSuj",
        "outputId": "01174eee-4cee-4003-87f5-72d519131c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found. Using CPU.')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1VrG0L_F8tNT"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = \"/home/kwakrhkr59/XAI_WF/preprocessing/output/data.npz\"\n",
        "feature = \"size\"\n",
        "NB_EPOCH = 5\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "LENGTH = 5000\n",
        "OPTIMIZER = tf.keras.optimizers.legacy.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "INPUT_SHAPE = (LENGTH, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5dE-9hI-WpE",
        "outputId": "30cb58d9-4c0a-45a5-eebc-b908be4c344b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing data for training, and evaluating the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configured NB_CLASSES (75) does not match actual number of classes (95). Using 95.\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading and preparing data for training, and evaluating the model\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = load_npz(DATASET_DIR)\n",
        "NB_CLASSES = y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXrsZLcnIAlP",
        "outputId": "2deeb2b9-df76-44d4-a397-9b0bf2cef0e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15200, 5000, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdlArPbHH-Fi",
        "outputId": "48f3ec26-0dbe-44a1-fb32-006a9cab9a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (15200, 5000, 1)\n",
            "Shape of X_valid: (1900, 5000, 1)\n",
            "Shape of X_test: (1900, 5000, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train[:, :, 0].reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_valid = X_valid[:, :, 0].reshape(X_valid.shape[0], X_valid.shape[1], 1)\n",
        "X_test = X_test[:, :, 0].reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_valid:\", X_valid.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnIOzgpS-hjR",
        "outputId": "0e6e7717-6593-45e0-a611-0626221550c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building and training DF model\n",
            "Model compiled\n"
          ]
        }
      ],
      "source": [
        "print(\"Building and training DF model\")\n",
        "model = DFNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
        "print(\"Model compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ldEBlMCJyqe"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9bz1rE1D-jMQ",
        "outputId": "9eb6ea3b-b849-48f3-88c6-86942b4d4a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-30 23:15:40.075483: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
            "2025-06-30 23:15:40.079098: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
            "2025-06-30 23:15:40.079155: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
            "2025-06-30 23:15:40.079462: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
            "Relying on driver to perform ptx compilation. \n",
            "Modify $PATH to customize ptxas location.\n",
            "This message will be only logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "119/119 [==============================] - 12s 58ms/step - loss: 4.7869 - accuracy: 0.0297 - val_loss: 4.4967 - val_accuracy: 0.0221\n",
            "Epoch 2/5\n",
            "119/119 [==============================] - 5s 44ms/step - loss: 4.3800 - accuracy: 0.0590 - val_loss: 4.2816 - val_accuracy: 0.0642\n",
            "Epoch 3/5\n",
            "119/119 [==============================] - 5s 44ms/step - loss: 4.1493 - accuracy: 0.0797 - val_loss: 3.8564 - val_accuracy: 0.1263\n",
            "Epoch 4/5\n",
            "119/119 [==============================] - 5s 44ms/step - loss: 3.9571 - accuracy: 0.1028 - val_loss: 3.9720 - val_accuracy: 0.1174\n",
            "Epoch 5/5\n",
            "119/119 [==============================] - 5s 44ms/step - loss: 3.7731 - accuracy: 0.1299 - val_loss: 3.6716 - val_accuracy: 0.1558\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NB_EPOCH,\n",
        "    verbose=VERBOSE,\n",
        "    validation_data=(X_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "obeR1ISf-kYc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 1s 7ms/step - loss: 3.6909 - accuracy: 0.1537\n",
            "60/60 [==============================] - 1s 4ms/step\n",
            "Testing accuracy: 0.1537\n",
            "Testing loss: 3.6909\n"
          ]
        }
      ],
      "source": [
        "score_test = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"Testing accuracy: {score_test[1]:.4f}\")\n",
        "print(f\"Testing loss: {score_test[0]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3goWvEqC-vXW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_history(history, score_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYa9LGur8RUw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating LRP visualizations for test samples...\n",
            "\n",
            "Processing LRP for class: Class_0\n",
            "1/1 [==============================] - 0s 155ms/step\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'innvestigate.utils' has no attribute 'model_wo_softmax'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data_sample_for_lrp)\n\u001b[1;32m     74\u001b[0m predicted_label_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(preds[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 75\u001b[0m lrp_relevance_map \u001b[38;5;241m=\u001b[39m \u001b[43mapply_lrp_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_sample_for_lrp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpred_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicted_label_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlrp.z\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m sample_title \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_class_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_idx_in_class\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[true_label_idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / Pred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[predicted_label_idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m plot_lrp_relevance(np\u001b[38;5;241m.\u001b[39msqueeze(X_test[i]), lrp_relevance_map,\n\u001b[1;32m     81\u001b[0m                    title\u001b[38;5;241m=\u001b[39msample_title,\n\u001b[1;32m     82\u001b[0m                    output_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(lrp_output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLRP_Class_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Sample_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "Cell \u001b[0;32mIn[13], line 2\u001b[0m, in \u001b[0;36mapply_lrp_1d\u001b[0;34m(model, data_array, pred_index, method)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_lrp_1d\u001b[39m(model, data_array, pred_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlrp.z\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     model_wo_softmax \u001b[38;5;241m=\u001b[39m \u001b[43miutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_wo_softmax\u001b[49m(model)\n\u001b[1;32m      3\u001b[0m     analyzer \u001b[38;5;241m=\u001b[39m innvestigate\u001b[38;5;241m.\u001b[39mcreate_analyzer(method, model_wo_softmax, neuron_selection_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data_array)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'innvestigate.utils' has no attribute 'model_wo_softmax'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def apply_lrp_1d(model, data_array, pred_index=None, method=\"lrp.z\"):\n",
        "    model_wo_softmax = iutils.model_wo_softmax(model)\n",
        "    analyzer = innvestigate.create_analyzer(method, model_wo_softmax, neuron_selection_mode=\"index\")\n",
        "    preds = model.predict(data_array)\n",
        "    if pred_index is None:\n",
        "        pred_index = np.argmax(preds[0])\n",
        "    analysis = analyzer.analyze(data_array, neuron_selection=pred_index)\n",
        "    lrp_relevance = np.squeeze(np.sum(np.abs(analysis[0]), axis=-1))\n",
        "    max_relevance = lrp_relevance.max()\n",
        "    if max_relevance > 0:\n",
        "        lrp_relevance /= max_relevance\n",
        "    return lrp_relevance\n",
        "\n",
        "def plot_lrp_relevance(original_data, lrp_relevance, title=\"\", output_path=None, relevance_threshold=0.7):\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(original_data, color='blue', label='Original Data', linewidth=1.5)\n",
        "    highlight_indices = np.where(lrp_relevance > relevance_threshold)[0]\n",
        "    if len(highlight_indices) > 0:\n",
        "        breaks = np.where(np.diff(highlight_indices) != 1)[0] + 1\n",
        "        segments = np.split(highlight_indices, breaks)\n",
        "        first_segment = True\n",
        "        for segment in segments:\n",
        "            if len(segment) > 0:\n",
        "                start_idx = segment[0]\n",
        "                end_idx = segment[-1]\n",
        "                plt.axvspan(start_idx, end_idx, color='red', alpha=0.3,\n",
        "                            label=f'High Relevance (>{relevance_threshold})' if first_segment else \"\")\n",
        "                first_segment = False\n",
        "    plt.title(f\"{title}\\nOriginal Data with LRP Highlights (Threshold: {relevance_threshold})\", fontsize=14)\n",
        "    plt.xlabel(\"Sequence Index\", fontsize=12)\n",
        "    plt.ylabel(\"Value\", fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.bar(range(len(lrp_relevance)), lrp_relevance, width=1.0, color='darkorange', alpha=0.8, label='LRP Relevance Score')\n",
        "    plt.axhline(y=relevance_threshold, color='green', linestyle='--', label='Relevance Threshold', alpha=0.7)\n",
        "    plt.title(f\"LRP Relevance Score\", fontsize=14)\n",
        "    plt.xlabel(\"Sequence Index\", fontsize=12)\n",
        "    plt.ylabel(\"Relevance Score (0-1)\", fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    if output_path:\n",
        "        plt.savefig(output_path, dpi=300)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "lrp_output_dir = f\"results_lrp/{feature}_batch{BATCH_SIZE}_epoch{NB_EPOCH}_per_class/\"\n",
        "os.makedirs(lrp_output_dir, exist_ok=True)\n",
        "\n",
        "desired_samples_per_class = 5\n",
        "\n",
        "print(\"\\nGenerating LRP visualizations for test samples...\")\n",
        "\n",
        "class_names = [f\"Class_{i}\" for i in range(NB_CLASSES)]\n",
        "\n",
        "for class_idx in range(NB_CLASSES):\n",
        "    current_class_name = class_names[class_idx]\n",
        "    print(f\"\\nProcessing LRP for class: {current_class_name}\")\n",
        "    class_indices = np.where(y_test[:, class_idx] == 1)[0]\n",
        "    num_samples_to_plot = min(desired_samples_per_class, len(class_indices))\n",
        "    if num_samples_to_plot == 0:\n",
        "        print(f\"No samples found for class: {current_class_name} in test set. Skipping LRP.\")\n",
        "        continue\n",
        "    np.random.shuffle(class_indices)\n",
        "    for sample_idx_in_class in range(num_samples_to_plot):\n",
        "        i = class_indices[sample_idx_in_class]\n",
        "        data_sample_for_lrp = np.expand_dims(X_test[i], axis=0)\n",
        "        true_label_idx = np.argmax(y_test[i])\n",
        "        preds = model.predict(data_sample_for_lrp)\n",
        "        predicted_label_idx = np.argmax(preds[0])\n",
        "        lrp_relevance_map = apply_lrp_1d(model, data_sample_for_lrp,\n",
        "                                         pred_index=predicted_label_idx,\n",
        "                                         method=\"lrp.z\")\n",
        "        sample_title = (f\"{current_class_name} Sample {sample_idx_in_class+1}\\n\"\n",
        "                        f\"True: {class_names[true_label_idx]} / Pred: {class_names[predicted_label_idx]}\")\n",
        "        plot_lrp_relevance(np.squeeze(X_test[i]), lrp_relevance_map,\n",
        "                           title=sample_title,\n",
        "                           output_path=os.path.join(lrp_output_dir, f\"LRP_Class_{class_idx}_Sample_{i}.png\"))\n",
        "\n",
        "print(\"LRP visualizations generation completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cam",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
